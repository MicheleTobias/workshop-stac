---
title: "STAC Catalog Workshop"
format: html
editor: visual
---

# Downloading Satellite Data from SpatioTemporal Asset Catalogs (STAC)

Authors:

-   Michele Tobias, PhD - [University of California Davis DataLab](https://datalab.ucdavis.edu/)

-   Alex Mandel, PhD - [Development Seed](https://developmentseed.org/)

In this workshop, we'll use [NASA's Earthdata](https://www.earthdata.nasa.gov/) repository to learn how to:

1.  Get access to a STAC Catalog

2.  Search the catalog

3.  Download data from the catalog

4.  Perform a basic analysis

For our work today, we'll be working with data from [10 Mile Dunes](https://maps.app.goo.gl/8Qg3WD1xEbA4jKdZ8), a large coastal dune field in northern California. Why this area? Coastal California has many of the challenges you might face when working with satellite imagery. The one many people will encounter is cloud cover. Another is scatter from water or other irregular natural surfaces. This area also has a variety of land cover, including ocean, California coastal scrub, active sandy dunes, agriculture, and built up areas. But really, Michele just wanted to explore this area because she researches beach and dune plants. You can modify the code to work with your own area of interest.

## Set Up Your Project

### Configure Your Environment & Set Up Authentication

There are some things we need to do to get access to NASA's Earthdata, but we only need to do these things the first time we engage with this dataset. Another way to put this is that once we do these first steps, we probably don't need to do them again.

To get access to NASA Earthdata, we need to do the following steps:

1.  Sign up for an Earthdata Login account: <https://urs.earthdata.nasa.gov/>

### Install and Load Libraries

First, we need to install any R libraries we want to use. Next, we need to load those libraries. You might assume that if we install the library, we want to use it, but R doesn't automatically load libraries you just installed.

```{r}
# Install Packages
#install.packages(c("rstac", "terra", "httr", "RColorBrewer", "getPass", "earthdatalogin"))

# Load Libraries
library(rstac)          # interact with stac catalogs
library(terra)          # work with raster data
#library(httr)           # gets information from webpages
library(RColorBrewer)   # color pallets from Color Brewer, a library of colors designed for optimized readability in cartograhy
library(getPass)        # allows us to give the code our password without it printing to the console
library(earthdatalogin) # let's us authenticate to access NASA data
```

### Configure the GDAL Library

GDAL is the library that allows your computer to read many spatial data formats and can translate one format to another (for example, you can read a shapefile into your code and save it as a geopackage thanks to GDAL). We need to change some of the settings in the way the library works for this R session. Don't worry; it won't change how GDAL works with your other geospatial programs.

```{r}
# GDAL optimization for working with cloud-optimized data
setGDALconfig("GDAL_DISABLE_READDIR_ON_OPEN", "EMPTY_DIR")
setGDALconfig("CPL_VSIL_CURL_ALLOWED_EXTENSIONS", "TIF") 
```

### Authenticate NASA Earthdata

"Authenticate" is a fancy word meaning "log in" or "prove you should have access". We'll do this by making a function that uses your Earthdata username and password. We've set up the code to ask you for these items so you don't have to store them in code that might be shared in public repositories. But this means you'll need to pay attention and set it here or the rest of the code won't run (because you won't be authenticated).

First the code asks for our credentials.

```{r}
earthdata_username <- getPass("Earthdata User:")
earthdata_password <- getPass("Earthdata Password:")

# note: use the function readline() if you want to be able to see your inputs... we need to mask the instructors' credentials for the broadcast.
```

Now we run the authentication function inputting our username and password:

```{r}
earthdatalogin::edl_netrc(username = earthdata_username, password = earthdata_password)
```

## Search Harmonized Lansat Sentinel (HSL) Data

First, we need to connect to the Landsat STAC catalog endpoint.

<https://cmr.earthdata.nasa.gov/stac/LPCLOUD>

How did we find this url?

Finding the data on NASA EarthData Search <https://search.earthdata.nasa.gov/search?q=C2021957295-LPCLOUD>

This told us the name of the collection and which DAAC it's hosted at, LPDAAC, whose catalog is listed on <https://cmr.earthdata.nasa.gov/stac> as LPCLOUD

```{r}
nasa_stac <- stac("https://cmr.earthdata.nasa.gov/stac/LPCLOUD")
```

Now let's define our geographic area of interest as the area that includes 10 Mile Dunes:

```{r}
# minimum longitude, minimum latitude, maximum longitude, and maximum latitude ---> 10 Mile Dunes
# We need bbox defined for STAC queries
bbox = c( -123.824405, 39.485343, -123.748531, 39.556319)
# Later we'll need the same bbox as a Terra extent object for reading data
extent = ext(c(bbox[1],bbox[3],bbox[2],bbox[4]))

plot(extent, col="lightblue") #ok, not that interesting, but we know it plots a bounding box
```

Set our STAC search parameters: STAC url, collection name, bbox, time interval, and limit how many items we can find.

```{r}
search_hls <- stac_search(
  q = nasa_stac, # The STAC API url
  collections = "HLSS30.v2.0", # https://lpdaac.usgs.gov/products/hlss30v002/
  bbox = bbox, 
  datetime = "2023-06-01T00:00:00Z/2023-07-30T00:00:00Z",  # A closed interval: "2018-02-12T00:00:00Z/2018-03-18T12:31:12Z" 
  limit = 100
)
```

Run the search. (Note: NASA's STAC needs a "post", many other STAC servers can use "get" requests.)

```{r}
results_hls <- post_request(search_hls)

results_hls
```

Inspect the first element of the results:

```{r}
results_hls$features[[1]]
```

And, let's look at the properties of this first element:

```{r}
results_hls$features[[1]]$properties
```

We can see what the cloud cover property is called in the STAC record based on this output. Let's look at the cloud cover property, something that will be important for images in a coastal area.

```{r}
results_hls$features[[1]]$properties$`eo:cloud_cover`
```

What assets are available for a given item? USGS has [more information](https://lpdaac.usgs.gov/data/get-started-data/collection-overview/missions/harmonized-landsat-sentinel-2-hls-overview/#hls-naming-conventions) on the HLS website. You can think of "assets" as bands of an image or different layers of information.

```{r}
names(results_hls$features[[1]]$assets)
```

Now we can filter our results to only include scenes with low cloud cover by filtering the metadata returned in our search.

```{r}
results_hls <- items_filter(results_hls, properties$`eo:cloud_cover` < 10)

results_hls
```

# ANALYSIS Using HLS

Normalized Difference Vegetation Index (NDVI) is an index commonly used to investigate vegetation health. You may already be familiar with this tool. Another similar index, Normalized Difference Water Index (NDWI), is used to understand the water content of plants or soils in remotely sensed imagery. It might seem counter-intuitive, but sandy dunes hold a lot of water. We'll use NDWI to help us differentiate the dunes from other substrate in our images.

First, we'll set which assets we're interested in so we don't have to download all the assets.

Reminder: Items have assets - example: item = photo, asset = a specific band

```{r}
items <- assets_select(results_hls,
                       asset_names = c(
                         "B03", #green: 0.53 – 0.59
                         "B8A", #NIR narrow: 0.85 – 0.88
                         "B04"  #red: 0.64 – 0.67
                      ))
```

Now we'll get the URLs for the assets. URLs are how we'll request the assets from the API.

```{r}
urls<-assets_url(items)

urls
```

To decide which of these items we want to download, we need to glean information from the file names in the URLs. The letter B followed by a number (or alphanumeric code) tells us the band number. Another part of the file name contains the year.

We can also see that there are 3 bands per scene. To work with one scene we can filter down that url list to single STAC Item.

```{r}
urls<-assets_url(items$features[[1]])

urls
```

First, let's configure the Green band:

(Note: `vsi=TRUE` tells Terra that the file path is a URL not a local file)

```{r}
band_green <- rast(urls[1], vsi=TRUE) 
```

Now, we need to read only the extent that matches the bounding box. However there's a slight catch, we need to convert the extent to the same projection as the HLS scene before we read.

```{r}
utm_extent <- terra::project(extent, "epsg:4326", crs(band_green))
band_green_crop <- crop(band_green, utm_extent)
```

Now let's get the IR and Red bands too:

```{r}
band_red <- rast(urls[2], vsi=TRUE, win=utm_extent)
band_ir <- rast(urls[3], vsi=TRUE, win=utm_extent)
```

We can calculate Normalized Difference Water Index (NDWI) as:

NDWI = (Green -- NIR)/(Green + NIR)

We can write a function in R to calcuate any normalized difference index.

```{r}
normdiff <- function(x, y) {
  (x - y) / (x + y)
}
```

We just need to know which band to submit for the x and y inputs to toggle between indexes like NDWI and NDVI (normalized difference vegetation index).

```{r}
ndwi = normdiff(band_green_crop, band_ir) 
ndvi = normdiff(band_ir, band_red)
```

Let's look at the histogram of NDWI to understand the output better:

```{r}
hist(ndwi, breaks = 40)
```

Now let's look at the summary of the values in our NDWI raster:

```{r}
summary(ndwi) #<-- ok, so there's some weirdness here
```

There is something odd going on with our values. Why is the minimum -41 and the max 85.6? Shouldn't the range of this index be \[-1,1\]? Yes, it should, but the sunlight glinting off the tops of waves in the ocean does odd things. So we'll have to filter those results out since we suspect they are not useful and not indicative of anything we're interested in.

Let's check the Green band.

```{r}
hist(band_green_crop, breaks = 40)
```

Something similar is going on here - do you see the long tail?

NDVI should also have some issues given what we've already seen, so let's look.

```{r}
hist(ndvi, breaks = 40)
```

```{r}
summary(ndvi)
```

# PLOT HLS

In this section, we'll plot the data we've downloaded and calculated. We'll combine plots and apply color palettes.

## Plot NDWI

Make a layout with one big figure at the top and two smaller figures below. The first figure takes up 4 cells in the matrix.

We'll call three different plots to fill in the slots in our layout, using the range parameter to filter out values outside of the range of our indexes. Note that this plot looks better in R Studio rather than Quarto.

```{r}
layout(matrix(c(1,1,1,1,2,3), ncol=2, nrow=3, byrow=TRUE))
# 1
plot(ndwi, main="NDWI", range=c(-1,1), col=brewer.pal(name='Blues', n=9)) # the range parameter limits the plot to just values in the interval you give - good to filtering out outliers (which happen especially over the ocean)
# 2
plot(band_green_crop, main = "Green", col=brewer.pal(name='Greens', n=9))
# 3
plot(band_ir, main = "IR", col=brewer.pal(name='YlOrRd', n=9))
```

Do you see the darker blue areas on the land? Those areas are the dune field. They stand out easily from the other soil types surrounding them.

We'll do a similar process for the NDVI analysis:

```{r}
# Plot NDVI
layout(matrix(c(1,1,1,1,2,3), ncol=2, nrow=3, byrow=TRUE))

# 1
plot(ndvi, main="NDVI", range=c(-1,1), col=brewer.pal(name='Greens', n=9))
# 2
plot(band_red, main = "Red", col=brewer.pal(name='YlOrRd', n=9))
# 3
plot(band_ir, main = "IR", col=brewer.pal(name='YlOrRd', n=9))

```

The dunes don't have a lot of green vegetation, so they look lighter than the surrounding areas. Beach and dune vegetation tend to be more silver or gray in color to reflect excess light, like many Mediterranean plant species growing in harsh condition. However, this means they have reflectance properties more similar to sand than plants so even when vegetation is present, it's hard to find with NDVI.

## Citations & Further Reaading

[rstac Example](https://brazil-data-cube.github.io/rstac/)

[rstac Documentation](https://brazil-data-cube.github.io/rstac/reference/index.html)

[r-spatial STAC](https://r-spatial.org/r/2021/04/23/cloud-based-cubes.html)

[stac spec tutorial on querying](https://stacspec.org/en/tutorials/2-using-rstac-and-cql2-to-query-stac-api/)

[stac spec tutorial on downloading data](https://stacspec.org/en/tutorials/1-download-data-using-r/)

[Getting Started with Cloud-Native Harmonized Landsat Sentinel-2 (HLS) Data in R](https://lpdaac.usgs.gov/resources/e-learning/getting-started-with-cloud-native-harmonized-landsat-sentinel-2-hls-data-in-r/)
